\chapter{Week9}
\section{Monday for MAT3040}\index{Monday_lecture}
\paragraph{Reviewing}
\begin{itemize}
\item
$\mathcal{X}_T(x) = (x-\lambda_1)\cdots(x-\lambda_n)$ over $\mathbb{F}$ if and only if $T$ is triangularizable over $\mathbb{F}$.
\item
$m_T(x) = (x-\mu_1)\cdots(x-\mu_k)$, where $\mu_i$'s are distinct over $\mathbb{F}$ if and only if $T$ is diagonalizable over $\mathbb{F}$.

The converse for this statement is the proposition~(\ref{pro:8:2}). Let's focus on the proof for the forward direction.
\end{itemize}

\subsection{Remarks on Primary Decomposition Theorem}


\begin{theorem}[Primary Decomposition Theorem]
Let $T:V\to V$ be a linear operator 
with $\dim(V)<\infty$, and
\[
m_T(x) = [p_1(x)]^{e_1}\cdots[p_k(x)]^{e_k}
\]
where $p_i$'s are distinct, monic, irreducible polynomials.
Let $V_i=\ker(p_i(T)^{e_i})$, then
\begin{enumerate}
\item
each $V_i$ is $T$-invariant ($i.e., T(V_i)\le V_i$)
\item
$V=V_1\oplus\cdots\oplus V_k$
\item
$T\mid_{V_i}$ has the minimal polynomial $p_i(x)^{e_i}$.
\end{enumerate}
\end{theorem}

\begin{proof}
\begin{enumerate}
\item
$(1)$ follows from part~(2) for example~(\ref{exp:7:2}).
\item
Let $q_i(x)=[p_1(x)]^{e_1}\cdots\widehat{[p_i(x)]^{e_i}}\cdots[p_k(x)]^{e_k}:=m_T(x)/[p_i(x)]^{e_i}$, then it is clear that
\begin{enumerate}
\item
$\text{gcd}(q_1,\dots,q_k)=1$
\item
$\text{gcd}(q_i,p_i^{e_i})=1$
\item
$q_i\cdot p_i^{e_i}=m_T$
\item
If $i\ne j$, then $m_T(x)\mid q_i(x)q_j(x)$
\end{enumerate}

\begin{itemize}
\item
By (a) and Bezout's Theorem~(\ref{The:6:7}), there exists polynomials $a_1,\dots,a_k$ such that
\[
a_1(x)q_1(x)+\cdots+a_k(x)q_k(x)=1,
\]
which implies
\[
\underbrace{a_1(T)q_1(T)\bm v}_{\bm v_1}+\cdots+\underbrace{a_k(T)q_k(T)\bm v}_{\bm v_k}=\bm v
\]
Therefore, $\bm v=\bm v_1+\cdots+\bm v_k$ for our constructed $\bm v_1,\dots,\bm v_k$.
\item
Note that
\[
p_i(T)^{e_i}\bm v_i
=
p_i(T)^{e_i}a_i(T)q_i(T)\bm v
=a_i(T)[q_i(T)p_i(T)^{e_i}]\bm v=a_i(T)m_T(T)\bm v=\bm0,
\]
whcih implies $\bm v_i\in\ker([p_i(T)]^{e_i}):=V_i$, and therefore
\begin{equation}\label{Eq:9:1}
V=V_1+\cdots+V_k
\end{equation}
\item
To show that the summation in (\ref{Eq:9:1}) is essentially the direct sum, consider 
\begin{equation}\label{Eq:9:2}
\bm0=\bm v_1'+\cdots+\bm v_k',\quad
\forall \bm v_i'\in V_i.
\end{equation}
By (a) and Bezout's Theorem~(\ref{The:6:7}), there exists $b_i(x),c_i(x)$ such that
\[
b_i(x)q_i(x)+c_i(x)p_i(x)^{e_i}=1\implies
b_i(T)q_i(T)+c_i(T)p_i(T)^{e_i}=I,
\]
i.e.,
\[
b_i(T)q_i(T)\bm v_i'+c_i(T)p_i(T)^{e_i}\bm v_i'=b_i(T)q_i(T)\bm v_i'=\bm v_i'.
\]
Appying the mapping $b_i(T)q_i(T)$ into equality~(\ref{Eq:9:2}) both sides, $i=1,\dots,k$, we obtain
\begin{align*}
\bm0=b_i(T)q_i(T)\bm0&=
b_i(T)q_i(T)\bm v_1'+\cdots+b_i(T)q_i(T)\bm v_k'
\end{align*}
Note that all terms on RHS vanish except for $b_i(T)q_i(T)\bm v_i'=\bm v_i'$, since $q_i(x)=[p_1(x)]^{e_1}\cdots\widehat{[p_i(x)]^{e_i}}\cdots[p_k(x)]^{e_k}$ and $\bm v_j'\in\ker([p_j(x)]^{e_j})$.
Therefore, $\bm v_i'=0$ for $i=1,\dots,k$, i.e., $V = V_1\oplus \cdots\oplus V_k$.
\end{itemize}
\item
For any $\bm v_i\in V_i$, we have $p_i(T)^{e_i}\bm v_i=\bm0$, which implies $m_{T\mid V_i}(x)\mid p_i(x)^{e_i}$. Together with Corollary~(\ref{cor:8:1}), $m_{T\mid v_i}(x)=p_i(x)^{f_i}$ for some $1\le f_i\le e_i$.

Suppose on the contrary that there exists $f_i<e_i$ for some $i$, consider any $\bm v:=\bm v_1+\cdots+\bm v_k\in V$, and
\begin{align*}
p_1(T)^{f_1}\cdots p_k(T)^{f_k}\bm v
&=
p_1(T)^{f_1}\cdots p_k(T)^{f_k}(\bm v_1+\cdots+\bm v_k)
\end{align*}
The term on the RHS vanishes since $p_j(T)^{f_j}\bm v_j=\bm0$, which implies
\[
m_T\mid p_1^{f_1}\cdots p_k^{f_k},
\]
but there exists $i$ such that $e_i>f_i$, which is a contradiction.
\end{enumerate}
\end{proof}


\begin{corollary}
If $m_i(x) = (x-\mu_1)\cdots(x-\mu_k)$ over $\mathbb{F}$, where $\mu_i$'s are distinct, then $T$ is diagonalizable over $\mathbb{F}$. (the converse actually also holds, see proposition~(\ref{pro:8:2}))
\end{corollary}
\begin{proof}
By primary decomposition theorem,
\[
V=\underbrace{\ker(T-\mu_1 I)}_{V_1}\oplus\cdots\underbrace{\oplus\ker(T-\mu_kI)}_{V_k}
\]
Take $B_i$ as a basis of $V_i$, an $\mu_i$-eigenspace of $T$.
Then $B:=\cup_{i=1}^kB_i$ is a basis consisting of eigenvectors of $T$.

It's clear that $(T\mid_{V_i})_{\mathcal{B},\mathcal{B}}=\diag(\mu_i,\dots,\mu_i)$, and $T$ is diagonalizable with 
\[
(T)_{\mathcal{B},\mathcal{B}}
=
\diag((T\mid_{V_1})_{\mathcal{B},\mathcal{B}},\cdots,(T\mid_{V_k})_{\mathcal{B},\mathcal{B}}).
\]
\end{proof}

\begin{corollary}[Spectral Decomposition]\label{cor:9:2}
Suppose $T:V\to V$ is diagonalizable, then there exists a linear operator $p_i:V\to V$ for $1\le i\le k$ such that
\begin{itemize}
\item
$p_i^2=p_i$ (idempotent)
\item
$p_ip_j=0,\forall i\ne j$
\item
$\sum_{i=1}^kp_i=I$
\item
$p_iT=Tp_i,\forall i$
\end{itemize}
and scalars $\mu_1,\dots,\mu_k$ such that
\[
T=\mu_1p_1+\cdots+\mu_kp_k
\]
\end{corollary}

\begin{proof}
Diagonlization of $T$ is equivalent to say that $m_T(x) = (x-\mu_1)\cdots(x-\mu_k)$, where $\mu_i$'s are distinct.
Construct
\begin{itemize}
\item
$V_i:=\ker(T-\mu_iI)$
\item
$p_i:V\to V$ given by $p_i=a_i(T)q_i(T)$ as in the proof of primary decomposition theorem
\end{itemize}
Then:
\begin{itemize}
\item
$p_iT=Tp_i$ is obvious
\item
$\sum_{i=1}^kp_i=\sum_{i=1}^ka_i(T)q_i(T)=I$
\item
$p_ip_j = a_i(T)a_j(T)q_i(T)q_j(T):=a_i(T)a_j(T)s(T)m_T(T)=\bm0$
\item
$p_i^2 = p_i(p_1+\cdots+p_k) = p_i\cdot I=p_i$
\end{itemize}

For the last part, note that 
\begin{itemize}
\item
$p_iV\le V_i,\forall i$: 
for $\forall\bm v\in V$,
\[
(T-\mu_iI)p_i\bm v=(T-\mu_iI)a_i(T)q_i(T)\bm v
=
a_i(T)m_T(x)\bm v=\bm0
\]
Therefore, $p_iV\le\ker(T-\mu_i I)=V_i$
\item
Now, for all $\bm w\in V$, 
\begin{align*}
T\bm w&=T(p_1+\cdots+p_k)\bm w\\
&=Tp_1\bm w+\cdots+Tp_k\bm w\\
&=(\mu_1p_1)\bm w+\cdots+(\mu_kp_k)\bm w
\end{align*}
and therefore $T = \mu_1p_1+\cdots+\mu_kp_k$
\end{itemize}
\end{proof}

\paragraph{Organization of future two weeks}
We are interested in under which condition does the $T$ is diagonalizable.
One special case is $T=A$, where $\bm A$ is a symmetric matrix.
We will study normal operators, which includes the case for symmetric matrices.

Question: what happens if $m_T(x)$ contains repeated linear factors?
We will spend the next whole class to show the Jordan Normal Form:
\begin{theorem}[Jordan Normal Form]
Let $\mathbb{F}$ be algebraically closed field such that every linear operator $T:V\to V$ has the form
\[
m_T(x) = \prod_{i=1}^k(x-\lambda_i)^{e_i}
\]
where $\lambda_i$'s are distinct.

Then there exists basis $\mathcal{A}$ of $V$ such that
\[
(T)_{\mathcal{A},\mathcal{A}}
=
\diag(\bm J_1,\dots,\bm J_k)
\]
where
\[
\bm J_i=\begin{pmatrix}
\mu&1&0&0\\
0&\mu&1&0\\
0&\vdots&\ddots&\vdots\\
0&0&\cdots&\mu
\end{pmatrix}
\]
for some $\mu\in\{\lambda_1,\dots,\lambda_k\}$
\end{theorem}










